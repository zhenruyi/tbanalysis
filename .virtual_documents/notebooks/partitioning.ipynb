from sklearn.cluster import KMeans
# 导入必要的库
from sklearn.datasets import make_blobs  # 用于生成模拟聚类数据
import matplotlib.pyplot as plt  # 用于数据可视化

# 使用 make_blobs 生成模拟数据集
# make_blobs 是 scikit-learn 中用于生成聚类数据的函数
# 它可以生成多个簇（blobs），每个簇的数据点服从高斯分布（正态分布）
# 返回值：
#   - X: 数据点的坐标，形状为 (n_samples, n_features)
#   - _: 数据点的标签（即属于哪个簇），这里用 _ 忽略
X, _ = make_blobs(
    n_samples=300,  # 生成 300 个样本点
    centers=4,      # 生成 4 个簇（即 4 个中心点）
    cluster_std=0.60,  # 每个簇的标准差，控制簇的分布紧密程度
                       # 值越小，簇内的点越集中；值越大，簇内的点越分散
    random_state=0   # 随机种子，确保每次生成的数据集相同，便于复现实验结果
)

# 打印生成的数据
# X 是一个二维数组，形状为 (300, 2)，表示 300 个样本点，每个样本点有 2 个特征（x 和 y 坐标）
print("Generated Data (X):")
print(X)

# 可视化生成的数据
# 使用 matplotlib 绘制散点图，直观展示数据的分布
plt.figure(figsize=(8, 6))  # 设置画布大小
plt.scatter(
    X[:, 0],  # 所有样本点的第一个特征（x 坐标）
    X[:, 1],  # 所有样本点的第二个特征（y 坐标）
    s=50,     # 点的大小
    edgecolor='k'  # 点的边缘颜色为黑色
)
plt.title("Generated Data with 4 Clusters")  # 设置标题
plt.xlabel("Feature 1 (X)")  # 设置 x 轴标签
plt.ylabel("Feature 2 (Y)")  # 设置 y 轴标签
plt.grid(True)  # 显示网格
plt.show()  # 显示图像

# 数据示例：
# X 的每一行表示一个样本点的坐标，例如：
# array([[ 2.04940444,  0.84073272],
#        [ 1.15157493,  4.76883686],
#        [ 0.77672328,  4.66664743],
#        ...,
#        [ 9.20551979,  4.4813144 ],
#        [ 9.89620891,  3.79483681],
#        [ 9.37447406,  3.07902214]])
# 其中 [2.04940444, 0.84073272] 表示一个点的 x 坐标为 2.04940444，y 坐标为 0.84073272

# 应用场景：
# 1. 测试聚类算法：生成的数据集可以用于测试 K-means、DBSCAN 等聚类算法的性能。
# 2. 教学演示：用于演示聚类算法的原理和效果，帮助学生理解簇的概念和聚类过程。
# 3. 算法对比：通过调整 centers 和 cluster_std 参数，生成不同复杂度的数据集，用于对比不同聚类算法的鲁棒性和性能。

# 计算SSE
sse = []
K_range = range(1, 11)
for k in K_range:
    # 初始化 KMeans 聚类模型
    # KMeans 是 scikit-learn 中实现 K-means 聚类算法的类
    # K-means 是一种划分聚类算法，通过迭代优化将数据划分为 K 个簇
    kmeans = KMeans(
        n_clusters=k,       # 指定簇的数量 K，即希望将数据划分为多少个簇
        random_state=42,    # 随机种子，用于控制算法的随机性
                            # 设置固定的 random_state 可以确保每次运行代码时结果一致，便于复现实验
        n_init=10           # 指定算法运行的次数，每次使用不同的初始质心
                            # K-means 的结果受初始质心影响较大，n_init 表示尝试多次并选择最优结果
                            # 默认值为 10，表示运行 10 次并选择 SSE（误差平方和）最小的一次作为最终结果
    )

    # 参数详解：
    # - n_clusters: 必须指定的参数，表示簇的数量 K。
    # - random_state: 随机种子，确保结果可复现。
    # - n_init: 运行次数，用于减少初始质心对结果的影响。

    # 返回值：
    # kmeans 是一个 KMeans 模型对象，可以通过以下方法使用：
    # - kmeans.fit(X): 对数据 X 进行聚类。
    # - kmeans.predict(X): 预测新数据点的簇标签。
    # - kmeans.cluster_centers_: 获取聚类后的簇中心坐标。
    # - kmeans.labels_: 获取每个样本点的簇标签。

    # 示例：
    # 假设 k=3，表示将数据分为 3 个簇
    # 1. 初始化模型：
    #    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    # 2. 训练模型：
    #    kmeans.fit(X)
    # 3. 获取簇中心：
    #    centers = kmeans.cluster_centers_
    # 4. 获取每个样本点的簇标签：
    #    labels = kmeans.labels_

    # 注意事项：
    # - K-means 对初始质心敏感，设置 n_init 可以减少随机性影响。
    # - random_state 用于确保结果可复现，适合教学和实验场景。
    # - n_clusters 的选择可以通过肘部法则或轮廓系数等方法确定。
    kmeans.fit(X)
    sse.append(kmeans.inertia_)  # SSE存储在inertia_属性中

# 绘制肘部图
plt.figure(figsize=(8, 5))
plt.plot(K_range, sse, 'bo-', markersize=8)
plt.xlabel('Number of clusters (K)')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.title('Elbow Method For Optimal K')
plt.show()



